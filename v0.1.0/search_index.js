var documenterSearchIndex = {"docs":
[{"location":"features/multi-threading/#Multi-Threading-Guide","page":"Multi-threading","title":"Multi-Threading Guide","text":"AdaptiveArrayPools uses task_local_storage() for task-local isolation: each Julia Task gets its own independent pool. This design ensures thread safety when used correctly.","category":"section"},{"location":"features/multi-threading/#Table-of-Contents","page":"Multi-threading","title":"Table of Contents","text":"Understanding Julia's Task/Thread Model\nHow Pools Work with @threads\nSafe Patterns\nUnsafe Patterns\nWhy Task-Local (Not Thread-Local)?\nUser Responsibility\n\n","category":"section"},{"location":"features/multi-threading/#Understanding-Julia's-Task/Thread-Model","page":"Multi-threading","title":"Understanding Julia's Task/Thread Model","text":"Julia uses an M:N threading model where multiple Tasks (lightweight coroutines) can run on multiple OS threads.\n\n┌─────────────────────────────────────────────────────────────┐\n│                     Julia Process                            │\n│                                                              │\n│  Thread 1              Thread 2              Thread 3        │\n│  ┌─────────┐          ┌─────────┐          ┌─────────┐      │\n│  │ Task A  │          │ Task C  │          │ Task E  │      │\n│  │ (TLS-A) │          │ (TLS-C) │          │ (TLS-E) │      │\n│  └─────────┘          └─────────┘          └─────────┘      │\n│  ┌─────────┐          ┌─────────┐                           │\n│  │ Task B  │          │ Task D  │                           │\n│  │ (TLS-B) │          │ (TLS-D) │                           │\n│  └─────────┘          └─────────┘                           │\n└─────────────────────────────────────────────────────────────┘\n\nKey concepts:\n\nConcept Description\nThread OS-level execution unit. Fixed count at Julia startup.\nTask Julia's lightweight coroutine (Green Thread). Created dynamically.\ntasklocalstorage() Per-Task storage. Each Task has its own isolated TLS.","category":"section"},{"location":"features/multi-threading/#Important:-One-Thread-Can-Run-Multiple-Tasks","page":"Multi-threading","title":"Important: One Thread Can Run Multiple Tasks","text":"A single thread can execute multiple Tasks by switching between them at yield points (I/O, sleep(), yield(), etc.):\n\n# Both tasks run on Thread 1, interleaved!\ntask_a = @spawn begin\n    println(\"A start\")\n    sleep(0.1)      # yield point - switch to Task B\n    println(\"A end\")\nend\n\ntask_b = @spawn begin\n    println(\"B start\")\n    sleep(0.1)      # yield point - switch back to Task A\n    println(\"B end\")\nend\n\n# Output (single thread):\n# A start\n# B start\n# A end\n# B end\n\n","category":"section"},{"location":"features/multi-threading/#How-Pools-Work-with-@threads","page":"Multi-threading","title":"How Pools Work with @threads","text":"When you use Threads.@threads, Julia distributes iterations across threads. Each thread gets one Task that processes its assigned iterations.\n\nThreads.@threads for i in 1:100_000   (4 threads)\n│\n├─ Thread 1: Task-1 → Pool-1\n│   └─ Processes i = 1..25,000 (same pool reused for all!)\n│\n├─ Thread 2: Task-2 → Pool-2\n│   └─ Processes i = 25,001..50,000\n│\n├─ Thread 3: Task-3 → Pool-3\n│   └─ Processes i = 50,001..75,000\n│\n└─ Thread 4: Task-4 → Pool-4\n    └─ Processes i = 75,001..100,000\n\nTotal: 4 pools created, each reused ~25,000 times","category":"section"},{"location":"features/multi-threading/#Key-Insight","page":"Multi-threading","title":"Key Insight","text":"@threads creates one Task per thread (not one per iteration!)\nEach Task has its own task_local_storage() → its own pool\nWithin one @threads block, pools are efficiently reused\nCalling @threads multiple times creates new Tasks → new pools each time\n\n","category":"section"},{"location":"features/multi-threading/#Safe-Patterns","page":"Multi-threading","title":"Safe Patterns","text":"","category":"section"},{"location":"features/multi-threading/#Pattern-1:-@with_pool-Inside-@threads","page":"Multi-threading","title":"Pattern 1: @with_pool Inside @threads","text":"Threads.@threads for i in 1:N\n    @with_pool pool begin\n        a = acquire!(pool, Float64, 100)\n        # ... computation ...\n    end  # pool automatically rewinds\nend\n\nEach thread's Task gets its own pool. Safe and efficient.","category":"section"},{"location":"features/multi-threading/#Pattern-2:-Function-Defined-with-@with_pool","page":"Multi-threading","title":"Pattern 2: Function Defined with @with_pool","text":"# Define function with @with_pool\n@with_pool pool function inner_work(x)\n    tmp = acquire!(pool, Float64, length(x))\n    tmp .= x\n    return sum(tmp)\nend\n\n# Call from @threads - each thread gets its own pool\nThreads.@threads for i in 1:N\n    result = inner_work(data[i])\nend\n\nThe pool is created per-Task when the function is called, not when defined.","category":"section"},{"location":"features/multi-threading/#Pattern-3:-Nested-Functions","page":"Multi-threading","title":"Pattern 3: Nested Functions","text":"@with_pool outer_pool function outer_work(data)\n    # outer_pool belongs to Main Task\n    tmp = acquire!(outer_pool, Float64, 100)\n\n    Threads.@threads for i in 1:length(data)\n        # inner_work creates its own pool per thread\n        inner_work(data[i])  # Inner pool ≠ outer_pool (safe!)\n    end\nend\n\nOuter and inner pools are completely independent.\n\n","category":"section"},{"location":"features/multi-threading/#Unsafe-Patterns","page":"Multi-threading","title":"Unsafe Patterns","text":"","category":"section"},{"location":"features/multi-threading/#Pattern-1:-@with_pool-Outside-@threads","page":"Multi-threading","title":"Pattern 1: @with_pool Outside @threads","text":"# ❌ DANGER: Race condition!\n@with_pool pool Threads.@threads for i in 1:N\n    a = acquire!(pool, Float64, 100)  # All threads share ONE pool!\nend\n\nWhy it fails: pool is created in the Main Task's TLS. All threads access the same pool simultaneously.","category":"section"},{"location":"features/multi-threading/#Pattern-2:-Sharing-Pool-Reference","page":"Multi-threading","title":"Pattern 2: Sharing Pool Reference","text":"# ❌ DANGER: Race condition!\npool = get_task_local_pool()  # Main Task's pool\nThreads.@threads for i in 1:N\n    a = acquire!(pool, Float64, 100)  # Shared access!\nend","category":"section"},{"location":"features/multi-threading/#Pattern-3:-Passing-Pool-to-@spawn","page":"Multi-threading","title":"Pattern 3: Passing Pool to @spawn","text":"# ❌ DANGER: Race condition!\n@with_pool pool begin\n    tasks = [Threads.@spawn begin\n        a = acquire!(pool, Float64, 100)  # Multiple tasks, one pool!\n    end for _ in 1:4]\n    wait.(tasks)\nend\n\n","category":"section"},{"location":"features/multi-threading/#Why-Task-Local-(Not-Thread-Local)?","page":"Multi-threading","title":"Why Task-Local (Not Thread-Local)?","text":"You might wonder: \"Why not use thread-local pools? They persist across @threads calls!\"","category":"section"},{"location":"features/multi-threading/#The-Stack-Discipline-Problem","page":"Multi-threading","title":"The Stack Discipline Problem","text":"AdaptiveArrayPools uses checkpoint! and rewind! - a stack-based allocation system:\n\n@with_pool pool begin\n    checkpoint!(pool)  # Push current state\n    a = acquire!(pool, ...)\n    b = acquire!(pool, ...)\n    # ...\n    rewind!(pool)      # Pop and restore state (LIFO!)\nend\n\nThis requires strict LIFO ordering: the Task that checkpoints first must rewind last.","category":"section"},{"location":"features/multi-threading/#Why-Thread-Local-Fails-with-@spawn","page":"Multi-threading","title":"Why Thread-Local Fails with @spawn","text":"With @spawn, multiple Tasks can interleave on the same thread:\n\nThread 1 (with Thread-Local Pool):\n\nTime →\nTask A: checkpoint! ──── acquire! ──── sleep ────────────── rewind!\nTask B:        checkpoint! ──── acquire! ──── sleep ──── rewind!\n                                                    ↑\n                                           A finishes first!\n\nStack corruption occurs:\n\nTask A: checkpoint! → stack = [0]\nTask B: checkpoint! → stack = [0, 1]\nTask A: rewind! → pops 1 (B's checkpoint!) → stack = [0]\nTask B: rewind! → pops 0 (A's checkpoint!) → WRONG!\n\nResult: B's arrays may be reused while B is still using them → memory corruption.","category":"section"},{"location":"features/multi-threading/#Locks-Don't-Help","page":"Multi-threading","title":"Locks Don't Help","text":"Adding locks only prevents simultaneous access, not LIFO violations. The stack still gets corrupted because Tasks finish in unpredictable order.","category":"section"},{"location":"features/multi-threading/#Task-Local:-The-Only-Safe-Solution","page":"Multi-threading","title":"Task-Local: The Only Safe Solution","text":"With Task-local pools:\n\nEach Task has its own pool\nEach pool has its own stack\nNo interleaving possible → LIFO always preserved\n\n","category":"section"},{"location":"features/multi-threading/#User-Responsibility","page":"Multi-threading","title":"User Responsibility","text":"","category":"section"},{"location":"features/multi-threading/#The-Core-Rule","page":"Multi-threading","title":"The Core Rule","text":"Pool objects must not be shared across Tasks.\n\nThis library prioritizes zero-overhead performance over runtime safety checks. No locks are added because:\n\nLocks would defeat the purpose of zero-allocation pooling\nEven with locks, stack corruption would occur (LIFO violations)","category":"section"},{"location":"features/multi-threading/#Quick-Reference","page":"Multi-threading","title":"Quick Reference","text":"Pattern Safety Reason\n@with_pool inside @threads ✅ Safe Each Task gets own pool\n@with_pool outside @threads ❌ Unsafe All threads share one pool\nFunction with @with_pool called from @threads ✅ Safe Pool created per-Task at call time\nPassing pool to @spawn ❌ Unsafe Multiple Tasks access same pool\nNested @with_pool (outer/inner) ✅ Safe Each level has independent pool","category":"section"},{"location":"features/multi-threading/#Debugging-Tips","page":"Multi-threading","title":"Debugging Tips","text":"If you encounter unexpected behavior:\n\nCheck pool placement: Is @with_pool inside or outside @threads?\nCheck pool sharing: Is the same pool variable accessed from multiple Tasks?\nEnable POOL_DEBUG: POOL_DEBUG[] = true catches some (not all) misuse patterns\n\n","category":"section"},{"location":"features/multi-threading/#Summary","page":"Multi-threading","title":"Summary","text":"AdaptiveArrayPools uses Task-local isolation for thread safety\nEach Julia Task gets its own independent pool via task_local_storage()\n@threads creates one Task per thread → pools are reused within the block\nAlways place @with_pool inside @threads, not outside\nThread-local pools are not an alternative due to stack discipline requirements\nCorrect usage is the user's responsibility (no runtime checks for performance)","category":"section"},{"location":"advanced/pool-patterns/#Advanced-Pool-Patterns","page":"Pool Patterns","title":"Advanced Pool Patterns","text":"This page covers advanced usage patterns for experienced users.","category":"section"},{"location":"advanced/pool-patterns/#Calling-Other-@with_pool-Functions","page":"Pool Patterns","title":"Calling Other @with_pool Functions","text":"Each @with_pool function manages its own checkpoint. They can call each other freely:\n\n@with_pool pool function step1(n)\n    A = zeros!(pool, Float64, n)\n    fill!(A, 1.0)\n    return sum(A)\nend\n\n@with_pool pool function step2(n)\n    B = zeros!(pool, Float64, n)\n    fill!(B, 2.0)\n    return sum(B)\nend\n\n@with_pool pool function pipeline(n)\n    a = step1(n)   # step1's arrays marked for reuse when it returns\n    b = step2(n)   # step2's arrays marked for reuse when it returns\n    C = acquire!(pool, Float64, n)\n    fill!(C, a + b)\n    return sum(C)\nend","category":"section"},{"location":"advanced/pool-patterns/#Passing-Pool-as-Argument","page":"Pool Patterns","title":"Passing Pool as Argument","text":"For complex call hierarchies, use @with_pool only at the top level and pass the pool through function arguments:\n\n# Inner functions receive pool as argument - no @with_pool needed\nfunction compute_step!(pool, data, result)\n    temp = acquire!(pool, Float64, length(data))\n    temp .= data .* 2\n    result[] += sum(temp)\nend\n\nfunction process_chunk!(pool, chunk, result)\n    temp = zeros!(pool, Float64, length(chunk))\n    compute_step!(pool, chunk, temp)\n    result[] += sum(temp)\nend\n\n# Only the entry point uses @with_pool\n@with_pool pool function main_computation(chunks)\n    result = Ref(0.0)\n    for chunk in chunks\n        process_chunk!(pool, chunk, result)\n    end\n    return result[]\nend\n\nBenefits:\n\nSingle checkpoint/rewind at top level\nInner functions are simpler (no macro overhead)\nPool lifetime is explicit and controlled","category":"section"},{"location":"advanced/pool-patterns/#Direct-Pool-Access-in-Inner-Functions","page":"Pool Patterns","title":"Direct Pool Access in Inner Functions","text":"An alternative to passing pool as argument: inner functions call get_task_local_pool() directly, while a top-level @with_pool function controls the lifecycle.\n\n# Inner functions access pool directly - no argument needed\nfunction compute_step!(data, result)\n    pool = get_task_local_pool()  # Direct access\n    temp = acquire!(pool, Float64, length(data))\n    temp .= data .* 2\n    result[] += sum(temp)\n    # temp NOT released here - stays active\nend\n\nfunction process_chunk!(chunk, accumulator)\n    pool = get_task_local_pool()  # Direct access\n    buffer = zeros!(pool, Float64, length(chunk))\n    compute_step!(chunk, buffer)\n    accumulator[] += sum(buffer)\n    # buffer NOT released here - stays active\nend\n\n# Top-level controls lifecycle with @with_pool\n@with_pool pool function main_pipeline(chunks)\n    #  checkpoint!() ─────────────────────────────────┐\n    accumulator = Ref(0.0)                          # │\n    for chunk in chunks                             # │\n        process_chunk!(chunk, accumulator)          # │  All arrays from\n        # └─ compute_step! allocates temp           # │  inner functions\n        # └─ process_chunk! allocates buffer        # │  accumulate here\n    end                                             # │\n    return accumulator[]                            # │\n    #  rewind!() ─────────────────────────────────────┘\n    #     └─ ALL arrays (temp, buffer, ...) marked for reuse\nend","category":"section"},{"location":"advanced/pool-patterns/#Memory-Flow-Visualization","page":"Pool Patterns","title":"Memory Flow Visualization","text":"main_pipeline(chunks)          Inner Functions\n       │\n  checkpoint!()\n       │\n       ├──► process_chunk!()\n       │         │\n       │         ├──► get_task_local_pool() ──► buffer allocated\n       │         │\n       │         └──► compute_step!()\n       │                   │\n       │                   └──► get_task_local_pool() ──► temp allocated\n       │\n       ├──► process_chunk!()  (next iteration)\n       │         └──► ... more allocations ...\n       │\n       ▼\n    rewind!()  ◄─────── ALL arrays marked for reuse","category":"section"},{"location":"advanced/pool-patterns/#User-Responsibility-Warning","page":"Pool Patterns","title":"⚠️ User Responsibility Warning","text":"This pattern requires you to guarantee that inner functions are always called through a @with_pool entry point:\n\n# SAFE: Called through main_pipeline\nmain_pipeline(my_chunks)  # ✓ Lifecycle managed\n\n# DANGEROUS: Direct call without @with_pool wrapper\ncompute_step!(some_data, some_ref)  # ✗ No checkpoint/rewind!\n# └─ Arrays allocated but NEVER marked for reuse → pool grows unboundedly\n\nWhen to use this pattern:\n\nDeep call hierarchies where threading pool through every function is tedious\nPerformance-critical code where you want to avoid argument passing overhead\nYou can enforce that all entry points use @with_pool\n\nWhen to prefer \"Passing Pool as Argument\":\n\nFunctions may be called from various contexts (some pooled, some not)\nLibrary code where you can't control the caller\nYou want explicit documentation of pool dependency in function signatures","category":"section"},{"location":"advanced/pool-patterns/#Manual-Checkpoint/Rewind","page":"Pool Patterns","title":"Manual Checkpoint/Rewind","text":"For fine-grained control, use checkpoint! and rewind! directly:\n\nfunction manual_control()\n    pool = get_task_local_pool()\n\n    checkpoint!(pool)\n    try\n        A = acquire!(pool, Float64, 100)\n        B = acquire!(pool, Float64, 100)\n        # ... compute ...\n        return sum(A) + sum(B)\n    finally\n        rewind!(pool)\n    end\nend\n\nThis is what @with_pool generates internally. Use manual control when:\n\nIntegrating with existing try/catch blocks\nConditional checkpoint/rewind logic needed\nBuilding custom pool management abstractions","category":"section"},{"location":"advanced/pool-patterns/#Scope-Only-@with_pool","page":"Pool Patterns","title":"Scope-Only @with_pool","text":"You can omit the pool name when inner functions handle their own acquire:\n\n@with_pool p function step1()\n    v = acquire!(p, Float64, 100)\n    sum(v)\nend\n\n@with_pool p function step2()\n    v = acquire!(p, Float64, 200)\n    sum(v)\nend\n\n# Outer function just provides scope management\n@with_pool function orchestrate()\n    a = step1()\n    b = step2()\n    return a + b\nend\n\nThe name-less @with_pool still performs checkpoint/rewind but doesn't expose the pool variable. This is useful when you're orchestrating other @with_pool functions.","category":"section"},{"location":"advanced/pool-patterns/#See-Also","page":"Pool Patterns","title":"See Also","text":"@with_pool Patterns - Basic usage patterns\nSafety Rules - Scope rules","category":"section"},{"location":"architecture/how-it-works/#How-It-Works","page":"How It Works","title":"How It Works","text":"This page explains the core mechanisms that enable zero-allocation array reuse.","category":"section"},{"location":"architecture/how-it-works/#The-Zero-Allocation-Promise","page":"How It Works","title":"The Zero-Allocation Promise","text":"+-------------------------------------------------------------+\n|  Call 1 (warmup):                                           |\n|    checkpoint! --> acquire! x 3 --> rewind!                 |\n|         |                                                   |\n|         +-- backing memory allocated                        |\n|                                                             |\n|  Call 2+ (zero-alloc):                                      |\n|    checkpoint! --> acquire! x 3 --> rewind!                 |\n|         |                                                   |\n|         +-- same memory reused, 0 bytes allocated           |\n+-------------------------------------------------------------+","category":"section"},{"location":"architecture/how-it-works/#Checkpoint/Rewind-Lifecycle","page":"How It Works","title":"Checkpoint/Rewind Lifecycle","text":"The core mechanism that enables memory reuse:\n\n@with_pool pool function foo()\n    |\n    +---> checkpoint!(pool)     # Save current state (n_active counters)\n    |\n    |     A = acquire!(pool, ...)  # n_active += 1\n    |     B = acquire!(pool, ...)  # n_active += 1\n    |     C = acquire!(pool, ...)  # n_active += 1\n    |     ... compute ...\n    |\n    +---> rewind!(pool)         # Restore n_active, arrays available for reuse\nend\n\nOn repeated calls, the same memory is reused without any allocation.","category":"section"},{"location":"architecture/how-it-works/#Exception-Safety:-try...finally","page":"How It Works","title":"Exception Safety: try...finally","text":"The @with_pool macro generates code with exception-safe cleanup:\n\n# What you write:\n@with_pool pool begin\n    A = acquire!(pool, Float64, 100)\n    result = compute(A)\nend\n\n# What the macro generates:\nlet pool = get_task_local_pool()\n    checkpoint!(pool)\n    try\n        A = acquire!(pool, Float64, 100)\n        result = compute(A)\n    finally\n        rewind!(pool)  # Always executes, even on exception\n    end\nend\n\nKey guarantee: The finally block ensures rewind! is called even if an exception occurs, preventing memory leaks and state corruption.","category":"section"},{"location":"architecture/how-it-works/#Fixed-Slot-Type-Dispatch","page":"How It Works","title":"Fixed-Slot Type Dispatch","text":"To achieve zero-lookup overhead, common types have dedicated struct fields:\n\nstruct AdaptiveArrayPool\n    float64::TypedPool{Float64}\n    float32::TypedPool{Float32}\n    int64::TypedPool{Int64}\n    int32::TypedPool{Int32}\n    complexf64::TypedPool{ComplexF64}\n    complexf32::TypedPool{ComplexF32}\n    bool::TypedPool{Bool}\n    others::IdDict{DataType, Any}  # Fallback for rare types\nend\n\nWhen you call acquire!(pool, Float64, n), the compiler inlines directly to pool.float64 — no dictionary lookup, no type instability.","category":"section"},{"location":"architecture/how-it-works/#N-Way-Set-Associative-Cache","page":"How It Works","title":"N-Way Set Associative Cache","text":"For unsafe_acquire! (which returns native Array types), we use an N-way cache to reduce header allocation:\n\n                    CACHE_WAYS = 4 (default)\n                    ┌────┬────┬────┬────┐\nSlot 0 (Float64):   │way0│way1│way2│way3│  ← round-robin eviction\n                    └────┴────┴────┴────┘\n                    ┌────┬────┬────┬────┐\nSlot 1 (Float32):   │way0│way1│way2│way3│\n                    └────┴────┴────┴────┘\n                    ...","category":"section"},{"location":"architecture/how-it-works/#Cache-Lookup-Pseudocode","page":"How It Works","title":"Cache Lookup Pseudocode","text":"function unsafe_acquire!(pool, T, dims...)\n    typed_pool = get_typed_pool!(pool, T)\n    slot = n_active + 1\n    base = (slot - 1) * CACHE_WAYS\n\n    # Search all ways for matching dimensions\n    for k in 1:CACHE_WAYS\n        idx = base + k\n        if dims == typed_pool.nd_dims[idx]\n            # Cache hit! Check if underlying vector was resized\n            if pointer matches\n                return typed_pool.nd_arrays[idx]\n            end\n        end\n    end\n\n    # Cache miss: create new Array header, store in next way (round-robin)\n    way = typed_pool.nd_next_way[slot]\n    typed_pool.nd_next_way[slot] = (way + 1) % CACHE_WAYS\n    # ... create and cache Array ...\nend\n\nKey insight: Even on cache miss, only the Array header (~80-144 bytes) is allocated. The actual data memory is always reused from the pool.","category":"section"},{"location":"architecture/how-it-works/#View-vs-Array-Return-Types","page":"How It Works","title":"View vs Array Return Types","text":"Type stability is critical for performance. AdaptiveArrayPools provides two APIs:\n\nAPI 1D Return N-D Return Allocation\nacquire! SubArray{T,1} ReshapedArray{T,N} Always 0 bytes\nunsafe_acquire! Vector{T} Array{T,N} 0 bytes (hit) / ~100 bytes (miss)","category":"section"},{"location":"architecture/how-it-works/#Why-Two-APIs?","page":"How It Works","title":"Why Two APIs?","text":"acquire! (views) — The compiler can eliminate view wrappers entirely through SROA (Scalar Replacement of Aggregates) and escape analysis. This is why 1D SubArray and N-D ReshapedArray achieve true zero allocation.\n\nunsafe_acquire! (arrays) — Sometimes you need a concrete Array type:\n\nFFI/C interop requiring Ptr{T} from contiguous memory\nType signatures that explicitly require Array{T,N}\nAvoiding runtime dispatch in polymorphic code","category":"section"},{"location":"architecture/how-it-works/#Typed-Checkpoint/Rewind-Optimization","page":"How It Works","title":"Typed Checkpoint/Rewind Optimization","text":"When the @with_pool macro can statically determine which types are used, it generates optimized code:\n\n# If only Float64 is used in the block:\ncheckpoint!(pool, Float64)  # ~77% faster than full checkpoint\n# ... compute ...\nrewind!(pool, Float64)\n\nThis avoids iterating over all type slots and the others IdDict.","category":"section"},{"location":"architecture/how-it-works/#1-Based-Sentinel-Pattern","page":"How It Works","title":"1-Based Sentinel Pattern","text":"Internal state vectors use a sentinel at index 0 to eliminate isempty() checks:\n\n_checkpoint_n_active = [0]  # Sentinel at depth=0\n_checkpoint_depths = [0]    # Global scope marker\n\nThis pattern reduces branching in hot paths where every nanosecond counts.","category":"section"},{"location":"architecture/how-it-works/#Further-Reading","page":"How It Works","title":"Further Reading","text":"For detailed design documents:\n\nhybrid_api_design.md — Two-API strategy (acquire! vs unsafe_acquire!) and type stability analysis\nnd_array_approach_comparison.md — N-way cache design, boxing analysis, and ReshapedArray benchmarks\nuntracked_acquire_design.md — Macro-based untracked acquire detection and 1-based sentinel pattern\nfixed_slots_codegen_design.md — Zero-allocation iteration via @generated functions\ncuda_extension_design.md — CUDA backend architecture and extension loading","category":"section"},{"location":"basics/safety-rules/#Safety-Rules","page":"Safety Rules","title":"Safety Rules","text":"AdaptiveArrayPools achieves zero allocation by reusing memory across calls. This requires understanding one critical rule.\n\n","category":"section"},{"location":"basics/safety-rules/#The-One-Rule","page":"Safety Rules","title":"The One Rule","text":"+-------------------------------------------------------------+\n|                                                             |\n|  Pool arrays are ONLY valid within their @with_pool scope   |\n|                                                             |\n|  When the scope ends, arrays are marked for reuse.          |\n|  Using arrays after scope ends = UNDEFINED BEHAVIOR         |\n|                                                             |\n+-------------------------------------------------------------+","category":"section"},{"location":"basics/safety-rules/#What's-Safe","page":"Safety Rules","title":"What's Safe","text":"Pattern Example Why It Works\nReturn computed values return sum(v) Scalar escapes, not the array\nReturn copies return copy(v) New allocation, independent data\nUse within scope result = A * B Arrays valid during computation","category":"section"},{"location":"basics/safety-rules/#What's-Dangerous","page":"Safety Rules","title":"What's Dangerous","text":"Pattern Example Why It Fails\nReturn array return v Array marked for reuse after return\nStore in global global_ref = v Points to reusable memory\nCapture in closure () -> sum(v) v may be overwritten when closure runs\n\n","category":"section"},{"location":"basics/safety-rules/#The-Scope-Rule-in-Detail","page":"Safety Rules","title":"The Scope Rule in Detail","text":"When @with_pool ends, all arrays acquired within that scope are marked available for reuse—not immediately freed. This is what makes zero-allocation possible on subsequent calls.\n\n@with_pool pool begin\n    v = acquire!(pool, Float64, 100)\n\n    result = sum(v)  # ✅ compute and return values\n    copied = copy(v) # ✅ copy if you need data outside\nend\n# v is no longer valid here - it's marked for reuse\n\nwarning: Why Undefined Behavior?\nAfter scope ends, using v is undefined because:Subsequent acquire! calls may overwrite the data — the memory is available for reuse\nTask termination may trigger GC — the pool itself could be garbage collected\nIt might \"work\" by luck — data unchanged until next acquire, but don't rely on thisThe worst case is silent data corruption: your code appears to work but produces wrong results intermittently.","category":"section"},{"location":"basics/safety-rules/#What-NOT-to-Do","page":"Safety Rules","title":"What NOT to Do","text":"","category":"section"},{"location":"basics/safety-rules/#Don't-return-pool-backed-arrays","page":"Safety Rules","title":"Don't return pool-backed arrays","text":"# ❌ Wrong: returning the array itself\n@with_pool pool function bad_example()\n    v = acquire!(pool, Float64, 100)\n    return v  # v marked for reuse after return!\nend\n\n# ✅ Correct: return computed values or copies\n@with_pool pool function good_example()\n    v = acquire!(pool, Float64, 100)\n    return sum(v)  # scalar result\nend","category":"section"},{"location":"basics/safety-rules/#Don't-store-in-globals-or-closures","page":"Safety Rules","title":"Don't store in globals or closures","text":"# ❌ Wrong: storing in global\nglobal_ref = nothing\n@with_pool pool begin\n    global_ref = acquire!(pool, Float64, 100)\nend\n# global_ref now points to reusable memory - data may be overwritten\n\n# ❌ Wrong: capturing in closure\n@with_pool pool begin\n    v = acquire!(pool, Float64, 100)\n    callback = () -> sum(v)  # v captured but may be overwritten later\nend","category":"section"},{"location":"basics/safety-rules/#Don't-resize-or-push!-to-unsafe_acquire!-arrays","page":"Safety Rules","title":"Don't resize or push! to unsafe_acquire! arrays","text":"@with_pool pool begin\n    v = unsafe_acquire!(pool, Float64, 100)\n    # ❌ These break pool memory management:\n    # resize!(v, 200)\n    # push!(v, 1.0)\n    # append!(v, [1.0, 2.0])\nend","category":"section"},{"location":"basics/safety-rules/#Debugging-with-POOL_DEBUG","page":"Safety Rules","title":"Debugging with POOL_DEBUG","text":"Enable runtime safety checks during development:\n\nusing AdaptiveArrayPools\nAdaptiveArrayPools.POOL_DEBUG[] = true\n\n@with_pool pool function test()\n    v = acquire!(pool, Float64, 100)\n    return v  # Will warn about returning pool-backed array\nend","category":"section"},{"location":"basics/safety-rules/#acquire!-vs-unsafe_acquire!","page":"Safety Rules","title":"acquire! vs unsafe_acquire!","text":"Function Returns Best For\nacquire! View types (SubArray, ReshapedArray) General use, BLAS/LAPACK\nunsafe_acquire! Native Array/CuArray FFI, type constraints\n\nBoth follow the same scope rules. Use acquire! by default—views work with all standard Julia linear algebra operations.","category":"section"},{"location":"basics/safety-rules/#Thread-Safety","page":"Safety Rules","title":"Thread Safety","text":"Pools are task-local, so each thread automatically gets its own pool:\n\n# ✅ Safe: each task has independent pool\nThreads.@threads for i in 1:N\n    @with_pool pool begin\n        a = acquire!(pool, Float64, 100)\n        # work with a...\n    end\nend\n\n# ❌ Unsafe: pool created outside threaded region\n@with_pool pool begin\n    Threads.@threads for i in 1:N\n        a = acquire!(pool, Float64, 100)  # race condition!\n    end\nend\n\nSee Multi-Threading for more patterns.","category":"section"},{"location":"basics/api-essentials/#Essential-API","page":"Essential API","title":"Essential API","text":"This page covers the core functions you'll use 99% of the time. For the complete API reference, see Full API.","category":"section"},{"location":"basics/api-essentials/#Array-Acquisition","page":"Essential API","title":"Array Acquisition","text":"","category":"section"},{"location":"basics/api-essentials/#acquire!(pool,-T,-dims...)","page":"Essential API","title":"acquire!(pool, T, dims...)","text":"The primary function. Returns a view (SubArray for 1D, ReshapedArray for N-D).\n\n@with_pool pool begin\n    v = acquire!(pool, Float64, 100)        # 1D: SubArray{Float64,1}\n    m = acquire!(pool, Float64, 10, 10)     # 2D: ReshapedArray{Float64,2}\n    t = acquire!(pool, Int64, 2, 3, 4)      # 3D: ReshapedArray{Int64,3}\nend\n\nAlways use acquire! by default. Views are zero-allocation and work with all BLAS/LAPACK operations.","category":"section"},{"location":"basics/api-essentials/#unsafe_acquire!(pool,-T,-dims...)","page":"Essential API","title":"unsafe_acquire!(pool, T, dims...)","text":"Returns a native Array type. Zero-allocation on cache hit—only allocates a small header (~80-144 bytes) on cache miss. Use when you specifically need Array{T,N}:\n\n@with_pool pool begin\n    # Use when you need Array for:\n    arr = unsafe_acquire!(pool, Float64, 100)\n\n    # - FFI/ccall requiring Ptr{T}\n    ccall(:some_c_function, Cvoid, (Ptr{Float64}, Cint), arr, length(arr))\n\n    # - Functions with strict Array{T,N} type signatures\nend\n\ntip: Cache behavior\nSame dimension pattern → 0 bytes. Different pattern → 80-144 bytes header only (data memory always reused). See N-Way Cache for details.","category":"section"},{"location":"basics/api-essentials/#Convenience-Functions","page":"Essential API","title":"Convenience Functions","text":"Zero-initialized arrays:\n\n@with_pool pool begin\n    z = zeros!(pool, Float64, 10, 10)   # All zeros\n    o = ones!(pool, Float64, 100)       # All ones\nend\n\nMatch existing array properties:\n\n@with_pool pool begin\n    A = acquire!(pool, Float64, 50, 50)\n    B = similar!(pool, A)                # Same type and size as A\n    C = similar!(pool, A, ComplexF64)    # Same size, different type\nend","category":"section"},{"location":"basics/api-essentials/#Custom-Initialization-with-fill!","page":"Essential API","title":"Custom Initialization with fill!","text":"For values other than 0 or 1, use Julia's built-in fill!:\n\n@with_pool pool begin\n    v = acquire!(pool, Float64, 100)\n    fill!(v, 3.14)              # Fill with pi\n\n    m = acquire!(pool, Int64, 10, 10)\n    fill!(m, -1)                # Fill with sentinel value\nend\n\nThis pattern works because pool arrays are mutable views into the underlying storage.","category":"section"},{"location":"basics/api-essentials/#Pool-Management","page":"Essential API","title":"Pool Management","text":"","category":"section"},{"location":"basics/api-essentials/#reset!(pool)","page":"Essential API","title":"reset!(pool)","text":"Releases all memory held by the pool. Useful for long-running processes:\n\n# After processing a large batch\n@with_pool pool begin\n    # ... large computation ...\nend\n\n# Optionally release memory if pool grew too large\nreset!(get_task_local_pool())","category":"section"},{"location":"basics/api-essentials/#pooling_enabled(pool)","page":"Essential API","title":"pooling_enabled(pool)","text":"Check if pooling is active (returns false for DisabledPool):\n\n@maybe_with_pool pool begin\n    if pooling_enabled(pool)\n        println(\"Using pool\")\n    else\n        println(\"Pooling disabled\")\n    end\nend","category":"section"},{"location":"basics/api-essentials/#Quick-Reference","page":"Essential API","title":"Quick Reference","text":"Function Returns Allocation Use Case\nacquire!(pool, T, dims...) View type 0 bytes Default choice\nunsafe_acquire!(pool, T, dims...) Array{T,N} 0 (hit) / 80-144 (miss) FFI, type constraints\nzeros!(pool, [T,] dims...) View type 0 bytes Zero-initialized\nones!(pool, [T,] dims...) View type 0 bytes One-initialized\nsimilar!(pool, A) View type 0 bytes Match existing array\nreset!(pool) nothing - Release all memory\npooling_enabled(pool) Bool - Check pool status","category":"section"},{"location":"basics/api-essentials/#See-Also","page":"Essential API","title":"See Also","text":"Full API Reference - Complete function list\n@with_pool Patterns - Usage patterns\nSafety Rules - Scope rules","category":"section"},{"location":"architecture/design-docs/#Design-Documents","page":"Design Documents","title":"Design Documents","text":"For in-depth analysis of design decisions, implementation tradeoffs, and architectural choices, see the design documents in the repository:","category":"section"},{"location":"architecture/design-docs/#API-Design","page":"Design Documents","title":"API Design","text":"hybridapidesign.md Two-API strategy (acquire! vs unsafe_acquire!) and type stability analysis","category":"section"},{"location":"architecture/design-docs/#Caching-and-Performance","page":"Design Documents","title":"Caching & Performance","text":"ndarrayapproach_comparison.md N-way cache design, boxing analysis, and ReshapedArray benchmarks\nfixedslotscodegen_design.md Zero-allocation iteration via @generated functions and fixed-slot type dispatch","category":"section"},{"location":"architecture/design-docs/#Macro-Internals","page":"Design Documents","title":"Macro Internals","text":"untrackedacquiredesign.md Macro-based untracked acquire detection and 1-based sentinel pattern","category":"section"},{"location":"architecture/design-docs/#Backend-Extensions","page":"Design Documents","title":"Backend Extensions","text":"cudaextensiondesign.md CUDA backend architecture and package extension loading\n\n","category":"section"},{"location":"architecture/design-docs/#Document-Overview","page":"Design Documents","title":"Document Overview","text":"Document Focus Area Key Insights\nhybridapidesign API strategy View types for zero-alloc, Array for FFI\nndarrayapproach_comparison Caching N-way associative cache reduces header allocation\nfixedslotscodegen_design Codegen @generated functions enable type-stable iteration\nuntrackedacquiredesign Macro safety Sentinel pattern ensures correct cleanup\ncudaextensiondesign GPU support Seamless CPU/CUDA API parity","category":"section"},{"location":"architecture/design-docs/#See-Also","page":"Design Documents","title":"See Also","text":"How It Works - High-level architecture overview\nType Dispatch & Cache - Technical deep-dive\n@with_pool Macro Internals - Macro transformation details","category":"section"},{"location":"features/configuration/#Configuration","page":"Configuration","title":"Configuration","text":"AdaptiveArrayPools can be configured via LocalPreferences.toml:\n\n[AdaptiveArrayPools]\nuse_pooling = false  # ⭐ Primary: Disable pooling entirely\ncache_ways = 8       # Advanced: N-way cache size (default: 4)","category":"section"},{"location":"features/configuration/#Compile-time:-USE_POOLING-(-Primary)","page":"Configuration","title":"Compile-time: USE_POOLING (⭐ Primary)","text":"The most important configuration. Completely disable pooling to make acquire! behave like standard allocation.\n\n# LocalPreferences.toml\n[AdaptiveArrayPools]\nuse_pooling = false\n\nOr programmatically:\n\nusing Preferences\nPreferences.set_preferences!(AdaptiveArrayPools, \"use_pooling\" => false)\n# Restart Julia for changes to take effect\n\nWhen USE_POOLING = false:\n\npool becomes DisabledPool{backend}() instead of an active pool\nAll pool functions fall back to standard allocation\nBackend context is preserved: :cuda still returns CuArray\n\n# These become equivalent:\n@with_pool pool acquire!(pool, Float64, n, n)  →  Matrix{Float64}(undef, n, n)\n@with_pool pool acquire!(pool, Float64, n)     →  Vector{Float64}(undef, n)\n\n# With CUDA backend:\n@with_pool :cuda pool zeros!(pool, 100)        →  CUDA.zeros(Float32, 100)\n\nUse pooling_enabled(pool) to check if pooling is active.\n\nUse cases:\n\nDebugging: Compare behavior with/without pooling\nBenchmarking: Measure pooling overhead vs direct allocation\nGradual adoption: Add @with_pool annotations now, enable pooling later\nCI/Testing: Run tests without pooling to isolate issues\n\nAll pooling code is completely eliminated at compile time (zero overhead).","category":"section"},{"location":"features/configuration/#Runtime:-MAYBE*POOLING*ENABLED","page":"Configuration","title":"Runtime: MAYBEPOOLINGENABLED","text":"Only affects @maybe_with_pool. Toggle without restart.\n\nMAYBE_POOLING_ENABLED[] = false  # Disable\nMAYBE_POOLING_ENABLED[] = true   # Enable (default)","category":"section"},{"location":"features/configuration/#Runtime:-POOL_DEBUG","page":"Configuration","title":"Runtime: POOL_DEBUG","text":"Enable safety validation to catch direct returns of pool-backed arrays.\n\nPOOL_DEBUG[] = true   # Enable safety checks (development)\nPOOL_DEBUG[] = false  # Disable (default, production)\n\nWhen enabled, returning a pool-backed array from a @with_pool block will throw an error.","category":"section"},{"location":"features/configuration/#Compile-time:-CACHE_WAYS","page":"Configuration","title":"Compile-time: CACHE_WAYS","text":"Configure the N-way cache size for unsafe_acquire!. Higher values reduce cache eviction but increase memory per slot.\n\n# LocalPreferences.toml\n[AdaptiveArrayPools]\ncache_ways = 8  # Default: 4, Range: 1-16\n\nOr programmatically:\n\nusing AdaptiveArrayPools\nset_cache_ways!(8)\n# Restart Julia for changes to take effect\n\nWhen to increase: If your code alternates between more than 4 dimension patterns per pool slot, increase cache_ways to avoid cache eviction (~100 bytes header per miss).\n\nScope: cache_ways affects all unsafe_acquire! calls (including 1D). Only acquire! 1D uses simple 1:1 caching.","category":"section"},{"location":"features/configuration/#Summary","page":"Configuration","title":"Summary","text":"Setting Scope Restart? Priority Affects\nuse_pooling Compile-time Yes ⭐ Primary All macros, acquire! behavior\ncache_ways Compile-time Yes Advanced unsafe_acquire! N-D caching\nMAYBE_POOLING_ENABLED Runtime No Optional @maybe_with_pool only\nPOOL_DEBUG Runtime No Debug Safety validation","category":"section"},{"location":"features/maybe-with-pool/#@maybe_with_pool","page":"@maybe_with_pool","title":"@maybe_with_pool","text":"Runtime-toggleable pooling. Users can enable/disable via MAYBE_POOLING_ENABLED[].","category":"section"},{"location":"features/maybe-with-pool/#Usage","page":"@maybe_with_pool","title":"Usage","text":"@maybe_with_pool pool function compute(n)\n    v = acquire!(pool, Float64, n)\n    v .= 1.0\n    sum(v)\nend\n\n# Toggle at runtime\nMAYBE_POOLING_ENABLED[] = false  # Normal allocation\nMAYBE_POOLING_ENABLED[] = true   # Uses pool","category":"section"},{"location":"features/maybe-with-pool/#When-to-Use","page":"@maybe_with_pool","title":"When to Use","text":"Library code where end-users should control pooling behavior\nDebugging: disable pooling to isolate memory issues\nBenchmarking: compare pooled vs non-pooled performance","category":"section"},{"location":"features/maybe-with-pool/#How-It-Works","page":"@maybe_with_pool","title":"How It Works","text":"When MAYBE_POOLING_ENABLED[] == false:\n\npool becomes DisabledPool{backend}() (e.g., DisabledPool{:cpu}() or DisabledPool{:cuda}())\nAll pool functions (acquire!, zeros!, etc.) fall back to standard allocation\nBackend context is preserved: :cuda → CuArray, :cpu → Array\n\nUse pooling_enabled(pool) to check if pooling is active:\n\n@maybe_with_pool pool begin\n    if pooling_enabled(pool)\n        # Using pooled memory\n    else\n        # Using standard allocation (DisabledPool)\n    end\nend","category":"section"},{"location":"features/maybe-with-pool/#vs-@with_pool","page":"@maybe_with_pool","title":"vs @with_pool","text":" @with_pool @maybe_with_pool\nRuntime toggle No Yes\nOverhead when disabled None Branch check\nUse case Application code Library code","category":"section"},{"location":"features/maybe-with-pool/#Safety","page":"@maybe_with_pool","title":"Safety","text":"Same rules as @with_pool: arrays are only valid within the scope. Do not return or store them externally.","category":"section"},{"location":"architecture/type-dispatch/#Type-Dispatch-and-Caching","page":"Type Dispatch & Cache","title":"Type Dispatch & Caching","text":"This page explains the internal mechanisms that enable zero-allocation performance.","category":"section"},{"location":"architecture/type-dispatch/#Fixed-Slot-Type-Dispatch","page":"Type Dispatch & Cache","title":"Fixed-Slot Type Dispatch","text":"To achieve zero-lookup overhead, common types have dedicated struct fields:\n\nstruct AdaptiveArrayPool\n    float64::TypedPool{Float64}\n    float32::TypedPool{Float32}\n    int64::TypedPool{Int64}\n    int32::TypedPool{Int32}\n    complexf64::TypedPool{ComplexF64}\n    complexf32::TypedPool{ComplexF32}\n    bool::TypedPool{Bool}\n    others::IdDict{DataType, Any}  # Fallback for rare types\nend\n\nWhen you call acquire!(pool, Float64, n), the compiler inlines directly to pool.float64 - no dictionary lookup, no type instability.","category":"section"},{"location":"architecture/type-dispatch/#N-Way-Set-Associative-Cache","page":"Type Dispatch & Cache","title":"N-Way Set Associative Cache","text":"For unsafe_acquire! (which returns native Array types), we use an N-way cache to reduce header allocation:\n\n                    CACHE_WAYS = 4 (default)\n                    +----+----+----+----+\nSlot 0 (Float64):   |way0|way1|way2|way3|  <-- round-robin eviction\n                    +----+----+----+----+\n                    +----+----+----+----+\nSlot 1 (Float32):   |way0|way1|way2|way3|\n                    +----+----+----+----+\n                    ...","category":"section"},{"location":"architecture/type-dispatch/#Cache-Lookup-Logic","page":"Type Dispatch & Cache","title":"Cache Lookup Logic","text":"function unsafe_acquire!(pool, T, dims...)\n    typed_pool = get_typed_pool!(pool, T)\n    slot = n_active + 1\n    base = (slot - 1) * CACHE_WAYS\n\n    # Search all ways for matching dimensions\n    for k in 1:CACHE_WAYS\n        idx = base + k\n        if dims == typed_pool.nd_dims[idx]\n            # Cache hit! Check if underlying vector was resized\n            if pointer matches\n                return typed_pool.nd_arrays[idx]\n            end\n        end\n    end\n\n    # Cache miss: create new Array header, store in next way (round-robin)\n    way = typed_pool.nd_next_way[slot]\n    typed_pool.nd_next_way[slot] = (way % CACHE_WAYS) + 1\n    # ... create and cache Array ...\nend\n\nKey insight: Even on cache miss, only the Array header (~80-144 bytes) is allocated. The actual data memory is always reused from the pool.\n\n","category":"section"},{"location":"architecture/type-dispatch/#View-vs-Array:-When-to-Use-What?","page":"Type Dispatch & Cache","title":"View vs Array: When to Use What?","text":"API Return Type Allocation Recommended For\nacquire! SubArray / ReshapedArray Always 0 bytes 99% of cases\nunsafe_acquire! Vector / Array 0-144 bytes FFI, type constraints","category":"section"},{"location":"architecture/type-dispatch/#Why-View-is-the-Default","page":"Type Dispatch & Cache","title":"Why View is the Default","text":"Zero-allocation guarantee: Compiler eliminates view wrappers via SROA (Scalar Replacement of Aggregates)\nBLAS/LAPACK compatible: Processed as StridedArray, no performance difference\nType stable: Always returns the same wrapper types","category":"section"},{"location":"architecture/type-dispatch/#When-to-Use-unsafe_acquire!","page":"Type Dispatch & Cache","title":"When to Use unsafe_acquire!","text":"C FFI: When ccall requires Ptr{T} from contiguous memory\n\narr = unsafe_acquire!(pool, Float64, 100)\nccall(:c_function, Cvoid, (Ptr{Float64}, Cint), arr, 100)\n\nType signature constraints: Function explicitly requires Array{T,N}\n\nfunction process(data::Array{Float64,2})\n    # Only accepts Array, not AbstractArray\nend\n\nm = unsafe_acquire!(pool, Float64, 10, 10)\nprocess(m)  # Works\n\nRuntime dispatch avoidance: When types are determined at runtime\n\n# Polymorphic code where type stability matters\nfunction dispatch_heavy(pool, T)\n    arr = unsafe_acquire!(pool, T, 100)  # Concrete Array type\n    # ... operations that would trigger dispatch with views\nend","category":"section"},{"location":"architecture/type-dispatch/#Performance-Comparison","page":"Type Dispatch & Cache","title":"Performance Comparison","text":"Operation acquire! (View) unsafe_acquire! (Array)\nAllocation (cached) 0 bytes 0 bytes\nAllocation (miss) 0 bytes 80-144 bytes\nBLAS operations Identical Identical\nType stability Guaranteed Guaranteed\nFFI compatibility Requires conversion Direct","category":"section"},{"location":"architecture/type-dispatch/#Header-Size-by-Dimensionality","page":"Type Dispatch & Cache","title":"Header Size by Dimensionality","text":"When unsafe_acquire! has a cache miss:\n\nDimensions Header Size\n1D (Vector) 80 bytes\n2D-3D 112 bytes\n4D-5D 144 bytes\n\nThis is Julia's internal Array metadata; actual data memory is always reused from the pool.\n\n","category":"section"},{"location":"architecture/type-dispatch/#See-Also","page":"Type Dispatch & Cache","title":"See Also","text":"How It Works - Checkpoint/Rewind mechanism\nDesign Documents - Detailed design analysis\nConfiguration - Cache tuning options","category":"section"},{"location":"architecture/macro-internals/#How-@with_pool-Works","page":"@with_pool Internals","title":"How @with_pool Works","text":"This page explains the internal mechanics of the @with_pool macro for advanced users and contributors who want to understand the optimization strategies.","category":"section"},{"location":"architecture/macro-internals/#Overview","page":"@with_pool Internals","title":"Overview","text":"The @with_pool macro provides automatic lifecycle management with three key optimizations:\n\nTry-Finally Safety — Guarantees cleanup even on exceptions\nTyped Checkpoint/Rewind — Only saves/restores used types (~77% faster)\nUntracked Acquire Detection — Safely handles acquire! calls outside macro visibility","category":"section"},{"location":"architecture/macro-internals/#Basic-Lifecycle-Flow","page":"@with_pool Internals","title":"Basic Lifecycle Flow","text":"┌─────────────────────────────────────────────────────────────┐\n│  @with_pool pool function foo(x)                            │\n│      A = acquire!(pool, Float64, 100)                       │\n│      B = similar!(pool, A)                                  │\n│      return sum(A) + sum(B)                                 │\n│  end                                                        │\n└─────────────────────────────────────────────────────────────┘\n                              ↓\n              ┌───────────────────────────────────┐\n              │       Macro Transformation        │\n              └───────────────────────────────────┘\n                              ↓\n┌─────────────────────────────────────────────────────────────┐\n│  function foo(x)                                            │\n│      pool = get_task_local_pool()                           │\n│      checkpoint!(pool, Float64)     # ← Type-specific       │\n│      try                                                    │\n│          A = _acquire_impl!(pool, Float64, 100)             │\n│          B = _similar_impl!(pool, A)                        │\n│          return sum(A) + sum(B)                             │\n│      finally                                                │\n│          rewind!(pool, Float64)     # ← Type-specific       │\n│      end                                                    │\n│  end                                                        │\n└─────────────────────────────────────────────────────────────┘","category":"section"},{"location":"architecture/macro-internals/#Key-Points","page":"@with_pool Internals","title":"Key Points","text":"try-finally ensures rewind! executes even if an exception occurs\nacquire! → _acquire_impl! transformation bypasses untracked marking overhead\nType-specific checkpoint!(pool, Float64) is ~77% faster than full checkpoint","category":"section"},{"location":"architecture/macro-internals/#Type-Extraction:-Static-Analysis-at-Compile-Time","page":"@with_pool Internals","title":"Type Extraction: Static Analysis at Compile Time","text":"The macro analyzes the AST to extract types used in acquire! calls:\n\n# Macro sees these acquire! calls:\n@with_pool pool begin\n    A = acquire!(pool, Float64, 10, 10)     # → extracts Float64\n    B = zeros!(pool, ComplexF64, 100)       # → extracts ComplexF64\n    C = similar!(pool, A)                    # → extracts eltype(A) → Float64\nend\n\n# Generated code uses typed checkpoint/rewind:\ncheckpoint!(pool, Float64, ComplexF64)\ntry\n    ...\nfinally\n    rewind!(pool, Float64, ComplexF64)\nend","category":"section"},{"location":"architecture/macro-internals/#Type-Extraction-Rules","page":"@with_pool Internals","title":"Type Extraction Rules","text":"Call Pattern Extracted Type\nacquire!(pool, Float64, dims...) Float64\nacquire!(pool, x) eltype(x) (if x is external)\nzeros!(pool, dims...) default_eltype(pool)\nzeros!(pool, Float32, dims...) Float32\nsimilar!(pool, x) eltype(x)\nsimilar!(pool, x, Int64, ...) Int64","category":"section"},{"location":"architecture/macro-internals/#When-Type-Extraction-Fails-Full-Checkpoint","page":"@with_pool Internals","title":"When Type Extraction Fails → Full Checkpoint","text":"The macro falls back to full checkpoint!(pool) when:\n\n@with_pool pool begin\n    T = eltype(data)                  # T defined locally AFTER checkpoint\n    A = acquire!(pool, T, 100)        # Can't use T at checkpoint time!\nend\n# → Falls back to checkpoint!(pool) / rewind!(pool)\n\n@with_pool pool begin\n    local_arr = compute()             # local_arr defined AFTER checkpoint\n    B = similar!(pool, local_arr)     # eltype(local_arr) unavailable\nend\n# → Falls back to checkpoint!(pool) / rewind!(pool)","category":"section"},{"location":"architecture/macro-internals/#Untracked-Acquire-Detection","page":"@with_pool Internals","title":"Untracked Acquire Detection","text":"","category":"section"},{"location":"architecture/macro-internals/#The-Problem","page":"@with_pool Internals","title":"The Problem","text":"The macro can only see acquire! calls directly in its AST. Calls inside helper functions are invisible:\n\nfunction helper!(pool)\n    return zeros!(pool, Float64, 100)   # Macro can't see this!\nend\n\n@with_pool pool begin\n    A = acquire!(pool, Int64, 10)       # ← Macro sees this (Int64)\n    B = helper!(pool)                    # ← Macro can't see Float64 inside!\nend\n\n# If only checkpoint!(pool, Int64), Float64 arrays won't be rewound!","category":"section"},{"location":"architecture/macro-internals/#The-Solution:-_untracked_flags","page":"@with_pool Internals","title":"The Solution: _untracked_flags","text":"Every acquire! call (and convenience functions) marks itself as \"untracked\":\n\n# Public API (called from user code outside macro)\n@inline function acquire!(pool, ::Type{T}, n::Int) where {T}\n    _mark_untracked!(pool)              # ← Sets flag!\n    _acquire_impl!(pool, T, n)\nend\n\n# Macro-transformed calls skip the marking\n# (because macro already knows about them)\n_acquire_impl!(pool, T, n)               # ← No flag","category":"section"},{"location":"architecture/macro-internals/#Flow-Diagram","page":"@with_pool Internals","title":"Flow Diagram","text":"@with_pool pool begin                    State of pool._untracked_flags\n    │                                    ─────────────────────────────────\n    ├─► checkpoint!(pool, Int64)         depth=2, flag[2]=false\n    │\n    │   A = _acquire_impl!(...)          (macro-transformed, no flag set)\n    │   B = helper!(pool)\n    │       └─► zeros!(pool, Float64, N)\n    │           └─► _mark_untracked!(pool)  flag[2]=TRUE ←──┐\n    │                                                        │\n    │   ... more code ...                                    │\n    │                                                        │\n    └─► rewind! check:                                       │\n        if pool._untracked_flags[2]  ─────────────────────────┘\n            rewind!(pool)            # Full rewind (safe)\n        else\n            rewind!(pool, Int64)     # Typed rewind (fast)\n        end\nend","category":"section"},{"location":"architecture/macro-internals/#Why-This-Works","page":"@with_pool Internals","title":"Why This Works","text":"Macro-tracked calls: Transformed to _acquire_impl! → no flag → typed rewind\nUntracked calls: Use public API → sets flag → triggers full rewind\nResult: Always safe, with optimization when possible","category":"section"},{"location":"architecture/macro-internals/#Nested-@with_pool-Handling","page":"@with_pool Internals","title":"Nested @with_pool Handling","text":"Each @with_pool maintains its own checkpoint depth:\n\n@with_pool p1 begin                      depth: 1 → 2\n    v1 = acquire!(p1, Float64, 10)\n    │\n    ├─► @with_pool p2 begin              depth: 2 → 3\n    │       v2 = acquire!(p2, Int64, 5)\n    │       helper!(p2)                  # sets flag[3]=true\n    │       sum(v2)\n    │   end                              depth: 3 → 2, flag[3] checked\n    │\n    │   # v1 still valid here!\n    sum(v1)\nend                                      depth: 2 → 1, flag[2] checked","category":"section"},{"location":"architecture/macro-internals/#Depth-Tracking-Data-Structures","page":"@with_pool Internals","title":"Depth Tracking Data Structures","text":"struct AdaptiveArrayPool\n    # ... type pools ...\n    _current_depth::Int              # Current scope depth (1 = global)\n    _untracked_flags::Vector{Bool}   # Per-depth flag array\nend\n\n# Initialized with sentinel:\n_current_depth = 1                   # Global scope\n_untracked_flags = [false]           # Sentinel for depth=1","category":"section"},{"location":"architecture/macro-internals/#Performance-Impact","page":"@with_pool Internals","title":"Performance Impact","text":"Scenario Checkpoint Method Relative Speed\n1 type, no untracked checkpoint!(pool, T) ~77% faster\nMultiple types, no untracked checkpoint!(pool, T1, T2, ...) ~50% faster\nAny untracked acquire checkpoint!(pool) Baseline\n\nThe optimization matters most in tight loops with many iterations.","category":"section"},{"location":"architecture/macro-internals/#Code-Generation-Summary","page":"@with_pool Internals","title":"Code Generation Summary","text":"# INPUT\n@with_pool pool function compute(data)\n    A = acquire!(pool, Float64, length(data))\n    result = helper!(pool, A)  # May have untracked acquires\n    return result\nend\n\n# OUTPUT (simplified)\nfunction compute(data)\n    pool = get_task_local_pool()\n\n    # Check if parent scope had untracked (for nested pools)\n    if pool._untracked_flags[pool._current_depth]\n        checkpoint!(pool)                    # Full checkpoint\n    else\n        checkpoint!(pool, Float64)           # Typed checkpoint\n    end\n\n    try\n        A = _acquire_impl!(pool, Float64, length(data))\n        result = helper!(pool, A)\n        return result\n    finally\n        # Check if untracked acquires occurred in this scope\n        if pool._untracked_flags[pool._current_depth]\n            rewind!(pool)                    # Full rewind\n        else\n            rewind!(pool, Float64)           # Typed rewind\n        end\n    end\nend","category":"section"},{"location":"architecture/macro-internals/#Key-Internal-Functions","page":"@with_pool Internals","title":"Key Internal Functions","text":"Function Purpose\n_extract_acquire_types(expr, pool_name) AST walk to find types\n_filter_static_types(types, local_vars) Filter out locally-defined types\n_transform_acquire_calls(expr, pool_name) Replace acquire! → _acquire_impl!\n_mark_untracked!(pool) Set untracked flag for current depth\n_generate_typed_checkpoint_call(pool, types) Generate checkpoint!(pool, T...)","category":"section"},{"location":"architecture/macro-internals/#See-Also","page":"@with_pool Internals","title":"See Also","text":"How It Works — Overview of pool architecture\nSafety Rules — Scope rules and best practices\nConfiguration — Performance tuning options","category":"section"},{"location":"basics/quick-start/#Quick-Start","page":"Quick Start","title":"Quick Start","text":"This guide will help you get up and running with AdaptiveArrayPools.jl in minutes.","category":"section"},{"location":"basics/quick-start/#Installation","page":"Quick Start","title":"Installation","text":"using Pkg\nPkg.Registry.add(Pkg.RegistrySpec(url=\"https://github.com/ProjectTorreyPines/FuseRegistry.jl.git\"))\nPkg.add(\"AdaptiveArrayPools\")","category":"section"},{"location":"basics/quick-start/#Basic-Usage","page":"Quick Start","title":"Basic Usage","text":"The core workflow is simple:\n\nWrap your function with @with_pool\nReplace allocations with acquire! or convenience functions\nReturn computed values (scalars, copies), not the arrays themselves","category":"section"},{"location":"basics/quick-start/#Before-(Standard-Julia)","page":"Quick Start","title":"Before (Standard Julia)","text":"function compute(n)\n    A = rand(n, n)      # allocates\n    B = rand(n, n)      # allocates\n    C = A * B           # allocates\n    return sum(C)\nend\n\nfor i in 1:10_000\n    compute(100)  # 90k allocations, 2.75 GiB, 31% GC time\nend","category":"section"},{"location":"basics/quick-start/#After-(With-Pooling)","page":"Quick Start","title":"After (With Pooling)","text":"using AdaptiveArrayPools, LinearAlgebra, Random\n\n@with_pool pool function compute_pooled(n)\n    A = acquire!(pool, Float64, n, n)  # reuses memory\n    B = similar!(pool, A)\n    C = similar!(pool, A)\n\n    rand!(A); rand!(B)\n    mul!(C, A, B)\n    return sum(C)\nend\n\ncompute_pooled(100)  # warmup (first call allocates)\nfor i in 1:10_000\n    compute_pooled(100)  # zero allocations, 0% GC\nend","category":"section"},{"location":"basics/quick-start/#Convenience-Functions","page":"Quick Start","title":"Convenience Functions","text":"Common initialization patterns have shortcuts:\n\nFunction Equivalent to\nzeros!(pool, 10) acquire! + fill!(0)\nones!(pool, Float32, 3, 3) acquire! + fill!(1)\nsimilar!(pool, A) acquire! matching eltype(A), size(A)\n\n@with_pool pool function example(n)\n    A = zeros!(pool, n, n)        # zero-initialized\n    B = ones!(pool, Float32, n)   # Float32 ones\n    C = similar!(pool, A)         # same type and size as A\n    # ...\nend","category":"section"},{"location":"basics/quick-start/#Return-Types","page":"Quick Start","title":"Return Types","text":"acquire! and convenience functions return view types (SubArray, ReshapedArray) that work seamlessly with BLAS/LAPACK:\n\nA = acquire!(pool, Float64, 10, 10)  # ReshapedArray{Float64,2}\nmul!(C, A, B)  # works perfectly with BLAS\n\nIf you need native Array types (FFI, type constraints), use unsafe_acquire!:\n\nA = unsafe_acquire!(pool, Float64, 10, 10)  # Array{Float64,2}","category":"section"},{"location":"basics/quick-start/#Important-Safety-Rules","page":"Quick Start","title":"Important Safety Rules","text":"Arrays from the pool are only valid within the @with_pool scope:\n\n# DO NOT return pool-backed arrays\n@with_pool pool function bad_example()\n    A = acquire!(pool, Float64, 10)\n    return A  # WRONG - A marked for reuse, data may be overwritten!\nend\n\n# Return computed values instead\n@with_pool pool function good_example()\n    A = acquire!(pool, Float64, 10)\n    return sum(A)  # OK - returning a scalar\nend\n\nFor complete safety guidelines, see Safety Rules.","category":"section"},{"location":"basics/quick-start/#Next-Steps","page":"Quick Start","title":"Next Steps","text":"Safety Rules - Complete scope rules and anti-patterns\nFull API Reference - Complete function and macro reference\nConfiguration - Preferences and cache tuning\nMulti-threading - Task/thread safety patterns\nCUDA Support - GPU backend usage","category":"section"},{"location":"features/cuda-support/#CUDA-Backend","page":"CUDA Support","title":"CUDA Backend","text":"AdaptiveArrayPools provides native CUDA support through a package extension that loads automatically when CUDA.jl is available.","category":"section"},{"location":"features/cuda-support/#Quick-Start","page":"CUDA Support","title":"Quick Start","text":"using AdaptiveArrayPools, CUDA\n\n# Use :cuda backend for GPU arrays\n@with_pool :cuda pool function gpu_computation(n)\n    A = acquire!(pool, Float64, n, n)  # CuArray view\n    B = acquire!(pool, Float64, n, n)  # CuArray view\n\n    fill!(A, 1.0)\n    fill!(B, 2.0)\n\n    return sum(A .+ B)\nend\n\n# Zero GPU allocation in hot loops\nfor i in 1:1000\n    gpu_computation(100)  # GPU memory reused from pool\nend","category":"section"},{"location":"features/cuda-support/#API","page":"CUDA Support","title":"API","text":"The CUDA backend uses the same API as CPU, with :cuda backend specifier:\n\nMacro/Function Description\n@with_pool :cuda pool expr GPU pool with automatic checkpoint/rewind\nacquire!(pool, T, dims...) Returns CuArray view (always 0 bytes GPU alloc)\nunsafe_acquire!(pool, T, dims...) Returns raw CuArray (for FFI/type constraints)\nget_task_local_cuda_pool() Returns the task-local CUDA pool\npool_stats(:cuda) Print CUDA pool statistics","category":"section"},{"location":"features/cuda-support/#Return-Types","page":"CUDA Support","title":"Return Types","text":"Function 1D Return N-D Return\nacquire! CuArray{T,1} (view) CuArray{T,N} (view)\nunsafe_acquire! CuArray{T,1} CuArray{T,N}","category":"section"},{"location":"features/cuda-support/#Allocation-Behavior","page":"CUDA Support","title":"Allocation Behavior","text":"GPU Memory: Always 0 bytes allocation after warmup. The underlying CuVector is resized as needed and reused.\n\nCPU Memory:\n\nCache hit (≤4 dimension patterns per slot): 0 bytes\nCache miss (>4 patterns): ~100 bytes for wrapper metadata\n\n# Example: 4 patterns fit in 4-way cache → zero CPU allocation\ndims_list = ((10, 10), (5, 20), (20, 5), (4, 25))\nfor dims in dims_list\n    @with_pool :cuda p begin\n        A = acquire!(p, Float64, dims...)\n        # Use A...\n    end\nend","category":"section"},{"location":"features/cuda-support/#Fixed-Slot-Types","page":"CUDA Support","title":"Fixed Slot Types","text":"Optimized types with pre-allocated slots (same as CPU):\n\nType Field\nFloat64 .float64\nFloat32 .float32\nFloat16 .float16\nInt64 .int64\nInt32 .int32\nComplexF64 .complexf64\nComplexF32 .complexf32\nBool .bool\n\nOther types use the fallback dictionary (.others).","category":"section"},{"location":"features/cuda-support/#Limitations","page":"CUDA Support","title":"Limitations","text":"No @maybe_with_pool :cuda: Runtime toggle not supported for CUDA backend\nTask-local only: Each Task gets its own CUDA pool, same as CPU\nSame device: All arrays in a pool use the same CUDA device","category":"section"},{"location":"features/cuda-support/#Example:-Matrix-Multiplication","page":"CUDA Support","title":"Example: Matrix Multiplication","text":"using AdaptiveArrayPools, CUDA, LinearAlgebra\n\n@with_pool :cuda pool function gpu_matmul(n)\n    A = acquire!(pool, Float64, n, n)\n    B = acquire!(pool, Float64, n, n)\n    C = acquire!(pool, Float64, n, n)\n\n    rand!(A); rand!(B)\n    mul!(C, A, B)\n\n    return sum(C)\nend\n\n# Warmup\ngpu_matmul(100)\n\n# Benchmark - zero GPU allocation\nusing BenchmarkTools\n@benchmark gpu_matmul(1000)","category":"section"},{"location":"features/cuda-support/#Debugging","page":"CUDA Support","title":"Debugging","text":"# Check pool state\npool_stats(:cuda)\n\n# Output:\n# CuAdaptiveArrayPool (device 0)\n#   Float64 (fixed) [GPU]\n#     slots: 3 (active: 0)\n#     elements: 30000 (234.375 KiB)","category":"section"},{"location":"reference/api/#API-Reference","page":"Full API","title":"API Reference","text":"","category":"section"},{"location":"reference/api/#Macros","page":"Full API","title":"Macros","text":"Macro Description\n@with_pool name expr Recommended. Injects a global, task-local pool named name. Automatically checkpoints and rewinds.\n@maybe_with_pool name expr Same as @with_pool, but can be toggled on/off at runtime via MAYBE_POOLING_ENABLED[].","category":"section"},{"location":"reference/api/#Functions","page":"Full API","title":"Functions","text":"Function Description\nacquire!(pool, T, dims...) Returns a view: SubArray{T,1} for 1D, ReshapedArray{T,N} for N-D. Always 0 bytes.\nacquire!(pool, T, dims::Tuple) Tuple overload for acquire! (e.g., acquire!(pool, T, size(x))).\nacquire!(pool, x::AbstractArray) Similar-style: acquires array matching eltype(x) and size(x).\nunsafe_acquire!(pool, T, dims...) Returns native Array/CuArray (CPU: Vector{T} for 1D, Array{T,N} for N-D). Only for FFI/type constraints.\nunsafe_acquire!(pool, T, dims::Tuple) Tuple overload for unsafe_acquire!.\nunsafe_acquire!(pool, x::AbstractArray) Similar-style: acquires raw array matching eltype(x) and size(x).\nacquire_view!(pool, T, dims...) Alias for acquire!. Returns view types.\nacquire_array!(pool, T, dims...) Alias for unsafe_acquire!. Returns Array for N-D.\ncheckpoint!(pool) Saves the current pool state (stack pointer).\ncheckpoint!(pool, T...) Type-specific checkpoint for optimized performance.\nrewind!(pool) Restores the pool to the last checkpoint, freeing all arrays acquired since then.\nrewind!(pool, T...) Type-specific rewind for optimized performance.\npool_stats(pool) Prints detailed statistics about pool usage.\nget_task_local_pool() Returns the task-local pool instance.\nempty!(pool) Clears all internal storage, releasing all memory.","category":"section"},{"location":"reference/api/#Convenience-Functions","page":"Full API","title":"Convenience Functions","text":"Shortcuts for common acquire! + initialization patterns. Default element type is Float64 (CPU) or Float32 (CUDA).","category":"section"},{"location":"reference/api/#View-returning-(like-acquire!)","page":"Full API","title":"View-returning (like acquire!)","text":"Function Description\nzeros!(pool, [T,] dims...) Zero-initialized view. Equivalent to acquire! + fill!(0).\nones!(pool, [T,] dims...) One-initialized view. Equivalent to acquire! + fill!(1).\nsimilar!(pool, A) View matching eltype(A) and size(A).\nsimilar!(pool, A, T) View with type T, size from A.\nsimilar!(pool, A, dims...) View with eltype(A), specified dimensions.\nsimilar!(pool, A, T, dims...) View with type T, specified dimensions.","category":"section"},{"location":"reference/api/#Array-returning-(like-unsafe_acquire!)","page":"Full API","title":"Array-returning (like unsafe_acquire!)","text":"Function Description\nunsafe_zeros!(pool, [T,] dims...) Zero-initialized raw Array.\nunsafe_ones!(pool, [T,] dims...) One-initialized raw Array.\nunsafe_similar!(pool, A, ...) Raw Array with same signatures as similar!.\n\nAll convenience functions support tuple dimensions: zeros!(pool, (3, 4)).\n\nCUDA note: Default type is Float32 to match CUDA.zeros() behavior.","category":"section"},{"location":"reference/api/#Types","page":"Full API","title":"Types","text":"Type Description\nAdaptiveArrayPool The main pool type. Create with AdaptiveArrayPool().\nDisabledPool{Backend} Sentinel type when pooling is disabled. Preserves backend context (:cpu or :cuda).","category":"section"},{"location":"reference/api/#Utility-Functions","page":"Full API","title":"Utility Functions","text":"Function Description\npooling_enabled(pool) Returns true if pool is active, false if DisabledPool. Use instead of pool === nothing.\ndefault_eltype(pool) Returns default element type: Float64 (CPU) or Float32 (CUDA).","category":"section"},{"location":"reference/api/#Constants","page":"Full API","title":"Constants","text":"Constant Description\nUSE_POOLING Compile-time constant. Set via Preferences.jl to disable all pooling.\nMAYBE_POOLING_ENABLED Runtime Ref{Bool}. Only affects @maybe_with_pool.\nPOOL_DEBUG Runtime Ref{Bool}. Enable safety validation for debugging.\nCACHE_WAYS Compile-time constant. N-way cache size for unsafe_acquire! (default: 4, range: 1-16).","category":"section"},{"location":"reference/api/#Configuration-Functions","page":"Full API","title":"Configuration Functions","text":"Function Description\nset_cache_ways!(n) Set N-way cache size. Requires Julia restart.","category":"section"},{"location":"reference/api/#Safety-Notes","page":"Full API","title":"Safety Notes","text":"Arrays acquired from a pool are only valid within the @with_pool scope. Do not:\n\nReturn pool-backed arrays from functions\nStore them in global variables\nCapture them in closures that outlive the scope\nCall resize!, push!, or append! on arrays from unsafe_acquire!\n\nUse POOL_DEBUG[] = true during development to catch direct returns of pool-backed arrays.","category":"section"},{"location":"reference/api/#acquire!-vs-unsafe_acquire!","page":"Full API","title":"acquire! vs unsafe_acquire!","text":"Function 1D Return N-D Return Allocation\nacquire! SubArray{T,1} ReshapedArray{T,N} Always 0 bytes (stack-based views)\nunsafe_acquire! Vector{T} Array{T,N} 0 bytes (hit) / ~100 bytes header (miss)\n\nBoth share the same underlying pool memory. Even on cache miss, only the Array header is allocated—data memory is always reused from the pool. Use acquire! by default—BLAS/LAPACK are fully optimized for StridedArray, so there's no performance difference.\n\nUse unsafe_acquire! only when you need a concrete Array type (FFI, type signatures, runtime dispatch).\n\nCaching:\n\nacquire! 1D uses simple 1:1 cache (reuses SubArray if same length)\nunsafe_acquire! (all dimensions) uses N-way cache (up to CACHE_WAYS, default: 4) per slot; exceeding this causes eviction\n\nHeader size by dimensionality: The ~100 bytes is an average. Actual Array header allocation varies: 1D → 80 bytes, 2D-3D → 112 bytes, 4D-5D → 144 bytes. This is Julia's internal Array metadata; actual data memory is always reused from the pool.","category":"section"},{"location":"basics/with-pool-patterns/#@with_pool-Patterns","page":"@with_pool Patterns","title":"@with_pool Patterns","text":"The @with_pool macro provides automatic memory lifecycle management. It supports two usage patterns depending on your needs.","category":"section"},{"location":"basics/with-pool-patterns/#Pool-Name:-Choose-Any-Identifier","page":"@with_pool Patterns","title":"Pool Name: Choose Any Identifier","text":"The first argument to @with_pool is a variable name you choose - it doesn't have to be pool:\n\n@with_pool p function foo() ... end\n@with_pool mypool function bar() ... end\n@with_pool scratch function baz() ... end\n\nUse whatever name makes your code clearest.","category":"section"},{"location":"basics/with-pool-patterns/#Pattern-1:-Function-Decorator","page":"@with_pool Patterns","title":"Pattern 1: Function Decorator","text":"Wraps an entire function with pool management:\n\n@with_pool pool function compute(n)\n    A = acquire!(pool, Float64, n, n)\n    B = zeros!(pool, Float64, n)\n    # ... compute ...\n    return sum(A) + sum(B)\nend\n\nresult = compute(100)  # Zero-allocation after warmup\n\nBest for: Functions that exclusively use pooled arrays, hot-path functions.","category":"section"},{"location":"basics/with-pool-patterns/#Pattern-2:-Block-Wrapper","page":"@with_pool Patterns","title":"Pattern 2: Block Wrapper","text":"Wraps only a portion of a function:\n\nfunction process_data(data)\n    n = length(data)\n\n    @with_pool pool begin\n        temp = acquire!(pool, Float64, n)\n        temp .= data .* 2\n        result = sum(temp)\n    end  # temp marked for reuse here\n\n    return result * 1.5\nend\n\nBest for: Functions with mixed allocation needs, gradual adoption.","category":"section"},{"location":"basics/with-pool-patterns/#Pattern-Comparison","page":"@with_pool Patterns","title":"Pattern Comparison","text":"Aspect Function Decorator Block Wrapper\nScope Entire function begin...end block\nSyntax @with_pool pool function ... @with_pool pool begin ... end\nPool lifetime Function start to return Block entry to exit","category":"section"},{"location":"basics/with-pool-patterns/#Common-Mistakes","page":"@with_pool Patterns","title":"Common Mistakes","text":"# WRONG: returning the array itself\n@with_pool pool function bad()\n    v = acquire!(pool, Float64, 100)\n    return v  # v marked for reuse after return!\nend\n\n# CORRECT: return computed values\n@with_pool pool function good()\n    v = acquire!(pool, Float64, 100)\n    return sum(v)  # Scalar result is safe\nend\n\n# CORRECT: return a copy if you need the data\n@with_pool pool function also_good()\n    v = acquire!(pool, Float64, 100)\n    return copy(v)\nend","category":"section"},{"location":"basics/with-pool-patterns/#See-Also","page":"@with_pool Patterns","title":"See Also","text":"Essential API - Core functions for pool operations\nSafety Rules - Important scope rules","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: Stable) (Image: Dev) (Image: CI) (Image: codecov)","category":"section"},{"location":"#AdaptiveArrayPools.jl","page":"Home","title":"AdaptiveArrayPools.jl","text":"Zero-allocation temporary arrays for Julia.\n\nA lightweight library that lets you write natural, allocation-style code while automatically reusing memory behind the scenes. Eliminates GC pressure in hot loops without the complexity of manual buffer management.\n\nSupported backends:\n\nCPU — Array, works out of the box\nCUDA — CuArray, loads automatically when CUDA.jl is available","category":"section"},{"location":"#The-Problem","page":"Home","title":"The Problem","text":"In performance-critical code, temporary array allocations inside loops create massive GC pressure:\n\nfunction compute(n)\n    A = rand(n, n)      # allocates\n    B = rand(n, n)      # allocates\n    C = A * B           # allocates\n    return sum(C)\nend\n\nfor i in 1:10_000\n    compute(100)  # ⚠️ 90k allocations, 2.75 GiB, 31% GC time\nend\n\nThe traditional fix—passing pre-allocated buffers—works for simple cases but quickly becomes impractical:\n\nAPI pollution: Every function needs extra buffer arguments, breaking clean interfaces\nNested calls: Buffers must be threaded through entire call stacks, even third-party code\nDynamic shapes: Hard to pre-allocate when array sizes depend on runtime values\nPackage boundaries: You can't easily pass buffers into library functions you don't control","category":"section"},{"location":"#The-Solution","page":"Home","title":"The Solution","text":"Wrap your function with @with_pool and replace allocations with acquire! or convenience functions:\n\nusing AdaptiveArrayPools, LinearAlgebra, Random\n\n@with_pool pool function compute_pooled(n)\n    A = acquire!(pool, Float64, n, n)  # reuses memory from pool\n    B = similar!(pool, A)\n    C = similar!(pool, A)\n\n    rand!(A); rand!(B)\n    mul!(C, A, B)\n    return sum(C)\nend\n\ncompute_pooled(100)  # warmup\nfor i in 1:10_000\n    compute_pooled(100) # ✅ Zero allocations, 0% GC\nend\n\nMetric Standard AdaptiveArrayPools Improvement\nTime 787 ms 525 ms 1.5× faster\nAllocations ⚠️ 90,000 (2.75 GiB) ✅ 0 100% eliminated\nGC Time ⚠️ 31% ✅ 0% No GC pauses\n\nCUDA support: Same API—just use @with_pool :cuda pool. See CUDA Backend.","category":"section"},{"location":"#How-It-Works","page":"Home","title":"How It Works","text":"@with_pool automatically manages memory lifecycle for you:\n\nCheckpoint — Saves current pool state when entering the block\nAcquire — acquire! returns arrays backed by pooled memory\nRewind — When the block ends, all acquired arrays are marked available for reuse\n\nThis automatic checkpoint/rewind cycle is what enables zero allocation on repeated calls. You just write normal-looking code with acquire! instead of constructors.\n\nacquire! returns lightweight views (SubArray, ReshapedArray) that work seamlessly with BLAS/LAPACK. If you need native Array types (FFI, type constraints), use unsafe_acquire!—see API Reference.\n\nNote: Keeping acquired arrays inside the scope is your responsibility. Return computed values (scalars, copies), not the arrays themselves. See Safety Guide.\n\nThread-safe by design: Each Julia Task gets its own independent pool—no locks needed. See Multi-Threading for patterns.","category":"section"},{"location":"#Convenience-Functions","page":"Home","title":"Convenience Functions","text":"Common initialization patterns have convenience functions:\n\nFunction Equivalent to\nzeros!(pool, 10) acquire! + fill!(0)\nones!(pool, Float32, 3, 3) acquire! + fill!(1)\nsimilar!(pool, A) acquire! matching eltype(A), size(A)\n\nThese return views like acquire!. For raw Array types, use unsafe_acquire! or its convenience variants (unsafe_zeros!, unsafe_ones!, unsafe_similar!). See API Reference.","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"using Pkg\nPkg.Registry.add(Pkg.RegistrySpec(url=\"https://github.com/ProjectTorreyPines/FuseRegistry.jl.git\"))\nPkg.add(\"AdaptiveArrayPools\")","category":"section"},{"location":"#Documentation","page":"Home","title":"Documentation","text":"Guide Description\nAPI Reference Complete function and macro reference\nCUDA Backend GPU-specific usage and examples\nSafety Guide Scope rules and best practices\nMulti-Threading Task/thread safety patterns\nConfiguration Preferences and cache tuning","category":"section"},{"location":"#License","page":"Home","title":"License","text":"Apache 2.0","category":"section"},{"location":"#Contact","page":"Home","title":"Contact","text":"Min-Gu Yoo (Image: Linkedin) (General Atomics)  yoom@fusion.gat.com","category":"section"}]
}
